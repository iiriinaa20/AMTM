import os
from collections import defaultdict
import contractions
from nltk.corpus import stopwords

WORDS_DICT = []

TESTING_PATH = r"C:\Users\mihae\Desktop\Test"
DIRECTORY_PATH = r"C:\Users\mihae\Desktop\Train"
TRAIN_OUTPUT_PATH = r"C:\Users\mihae\Desktop\MASTER\out_train.txt"
TEST_OUTPUT_PATH = r"C:\Users\mihae\Desktop\MASTER\out_test.txt"
CONTRACTIONS_PATH = r"C:\Users\mihae\Desktop\MASTER\contractions.txt"
BGP1_OUTPUT_PATH = r"C:\Users\mihae\Desktop\MASTER\bgp1.txt"
FNB_OUTPUT_PATH = r"C:\Users\mihae\Desktop\MASTER\fnb.txt"
BGP2_OUTPUT_PATH = r"C:\Users\mihae\Desktop\MASTER\bgp2.txt"
MFPOS_OUTPUT_PATH = r"C:\Users\mihae\Desktop\MASTER\mfpos.txt"

STOP_WORDS = set(stopwords.words('english'))

OLD_POS = ""
FLAG_IS_CONTRACTED = False
FLAG_IS_FIRST_WORD = True

PUNCTUATION =  ['.',',','''"''',':',';','?','!','(',')','[',']','{','}','-','--']

correct_bayes = []
matrix = []
p_word_pos = []

POS_MAPPING = {
    'nouns': {'nn', 'nns', 'nps', 'np', 'nns$', 'nn$', 'nps$', 'np$','nna','nna$','nnc','nnc$','nr','nr$','nrs','nrs$','nnp','nnp$'},
    'verbs': {'vb','vba', 'vbd', 'vbg', 'vbn', 'vbp', 'vbz', 'hv', 'hvd', 'hvn', 'hvz', 'hvg', 'md','be','bed','bedz','beg','bem','ben','ber','bez',
              'vb*', 'vbd*', 'vbg*', 'vbn*', 'vbp*', 'vbz*', 'hv*', 'hvd*', 'hvn*', 'hvz*', 'hvg*', 'md*','be*','bed*','bedz*','beg*','bem*','ben*','ber*','bez*',
              'do','doz','dod','do*','doz*','dod*',},
    'adjectives': {'jj', 'jj$', 'jjr', 'jjt','jja','jjc','jjcc','jjs','jjf','jjm'},
    'adverbs': {'rb', 'rbr', 'rbt', 'ql', 'qlp', 'wrb', 'rb$'},
    'pronouns': {'ppss', 'pps', 'pp$', 'ppl', 'ppo', 'ppls', 'wp$', 'wpo', 'wql'},
    'determiners': {'dt','dti' ,'dtx', 'dts', 'dt$', 'at', 'abn', 'abx', 'ap', 'ap$','abl'},
    'prepositions': {'in'},
    'conjunctions': {'cc', 'cs'},
    'others': {'uh', 'ex', 'to', 'wdt', 'bez', 'nil', 'od', 'rn', '*'}
}

def read_contractions():
    
    CONTRACTIONS = {}
    with open(CONTRACTIONS_PATH, 'r', encoding='utf-8') as file:
        content = file.read().splitlines()
        for line in content:
            form0, form1 = line.split(":", 1)
            form1 = form1.split('|')[0].strip()
            CONTRACTIONS[form0.strip()] = form1
    print(f"CONTRACTIONS: {CONTRACTIONS}")
    CONTRACTIONS = read_contractions()
    
def fix_pos(pos):
    if '+' in pos:
        FLAG_IS_CONTRACTED = True
        pos = [pos.split('+')[0]]
    else:
        FLAG_IS_CONTRACTED = False
        pos = [pos]
    
    pos = [p[3:] if p.startswith('fw-') else p for p in pos]
    pos = [p[:-3] if p.endswith(('-hl', '-tl', '-nc')) else p for p in pos]
    pos = [p[:-3] if p.endswith(('-hl', '-tl', '-nc')) else p for p in pos]
    return pos

def separate_words_pos(current_word):
    global OLD_POS
    words = current_word.split('/')
    pos = words[-1]
    OLD_POS = pos  
    words = words[:-1]
    pos = fix_pos(pos)
    return words, pos

def map_pos(pos):
    for category, tags in POS_MAPPING.items():
        if pos in tags:
            return category
    return 'others' 

def process_words_no_contractions(words_list, pos_list, words_dict,is_Testing=False):
     global FLAG_IS_FIRST_WORD
     for word in words_list:
            if word.endswith(('.', '!', '?')):
                FLAG_IS_FIRST_WORD = True
            #mapped_pos = pos_list[0]
            mapped_pos = map_pos(pos_list[0])
            if word and word[0].isalpha() and word.lower() not in STOP_WORDS:
                    words_dict[(word.lower(),mapped_pos)] += 1
            if word and word[0].isalpha() and word.lower() in STOP_WORDS and words_dict[(word.lower(),mapped_pos)] == 0:
                    words_dict[(word.lower(),mapped_pos)] += 1

def read_brown(directory_path):
    words_dict = defaultdict(int)
    for file_name in os.listdir(directory_path):
        file_path = os.path.join(directory_path, file_name)
        if os.path.isfile(file_path):
            print(f"Reading file: {file_path}")
            with open(file_path, 'r') as fp:
                content = fp.read().splitlines()
                for line in content:
                    words = line.split()
                    for current_word in words:
                        current_word = current_word.lower()
                        words_list, pos_list = separate_words_pos(current_word)
                        process_words_no_contractions(words_list, pos_list, words_dict)
    return words_dict

def print_info(words_dict,IS_TESTING=False):
    
    distinct_words = len(words_dict)
    pos_tags = {pos for _, pos in words_dict}
    distinct_pos = len(pos_tags)
    total_count = sum(words_dict.values())
    single_occurrences = sum(1 for count in words_dict.values() if count == 1)
    frequency = defaultdict(int)
    if IS_TESTING:
        txt_file_path = TEST_OUTPUT_PATH
    else:
        txt_file_path = TRAIN_OUTPUT_PATH
        
        
    with open(txt_file_path, 'w') as file:
        
        file.write(f"distinct words: {distinct_words}\n")
        file.write(f"distint POS tags: {distinct_pos}\n")
        file.write(f"total words: {total_count}\n")
        file.write(f"words count 1: {single_occurrences}\n")
        
        file.write("\n\nfrequency:\n")
        for (word, pos), count in words_dict.items():
           frequency[pos] += count
           
        for pos, freq in frequency.items():
            file.write(f"{pos}: {freq}\n")
       
        file.write("\n\nPOS Tags:\n")
        for pos in pos_tags:
            file.write(f"{pos}\n")

        for (word, pos), count in words_dict.items():
            file.write(f"Word: {word}, PoS: {pos}, Count: {count}\n")
        
       
    print(f"***")


def bgp_probablities(words_dict):
    pos_probabilities = defaultdict(dict)
    word_totals = defaultdict(int)
    
    for (word, pos), count in words_dict.items():
        word_totals[word] += count
        if pos not in pos_probabilities[word]:
            pos_probabilities[word][pos] = 0
        pos_probabilities[word][pos] += count

    for word, pos_counts in pos_probabilities.items():
        for pos, count in pos_counts.items():
            if word_totals[word] > 0:
                pos_probabilities[word][pos] = count / word_totals[word]
            else:
                pos_probabilities[word][pos] = 0
    
    return pos_probabilities

def predict_pos_bgp(words, pos_probabilities, method='bgp1'):
    predictions = []
    for word in words:
        if word in pos_probabilities:
            best_pos = max(pos_probabilities[word], key=pos_probabilities[word].get)
        else:
            if method == 'bgp1':
                best_pos = 'others'
            else:
                best_pos = 'nouns'
        predictions.append((word, best_pos))
    
    return predictions

def most_freq_pos(words_dict):
    frequency = defaultdict(int)
    for _, pos in words_dict:
        frequency[pos] += 1
    most_frequent_pos = max(frequency, key=frequency.get)
    return most_frequent_pos

def predict_mfpos(words, most_frequent_pos):
    return [(word, most_frequent_pos) for word in words]

def calculate_metrics(predicted_tags, correct_tags):
    true_positive = false_positive = false_negative = true_negative = 0

    for (_, predicted_pos), correct_pos in zip(predicted_tags, correct_tags):
        if predicted_pos == correct_pos:
            true_positive += 1
        else:
            false_positive += 1
            false_negative += 1

    total = true_positive + false_positive + false_negative
    accuracy = true_positive / total if total > 0 else 0
    precision = true_positive / (true_positive + false_positive) if true_positive + false_positive > 0 else 0
    recall = true_positive / (true_positive + false_negative) if true_positive + false_negative > 0 else 0
    f_measure = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0

    return {
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall,
        "f_measure": f_measure
    }


def print_bgp1_output(correct_pos, words_to_predict):
    pos_probabilities = bgp_probablities(WORDS_DICT)  
    predicted_tags = predict_pos_bgp(words_to_predict, pos_probabilities)
    metrics = calculate_metrics(predicted_tags, correct_pos)

    with open(BGP1_OUTPUT_PATH, "w") as file:
        file.write("Word         Predicted POS         Correct POS\n")
        file.write("-" * 30 + "\n")
        for (word, predicted_pos), correct_pos_tag in zip(predicted_tags, correct_pos):
            file.write(f"{word}: {predicted_pos} - {correct_pos_tag}\n")
        file.write("\n")
        for metric, value in metrics.items():
            file.write(f"{metric}: {value}\n")

def print_bgp2_output(correct_pos, words_to_predict):
    pos_probabilities = bgp_probablities(WORDS_DICT)  
    predicted_tags = predict_pos_bgp(words_to_predict, pos_probabilities, method='bgp2')
    metrics = calculate_metrics(predicted_tags, correct_pos)

    with open(BGP2_OUTPUT_PATH, "w") as file:
        file.write("Word         Predicted POS         Correct POS\n")
        file.write("-" * 30 + "\n")
        for (word, predicted_pos), correct_pos_tag in zip(predicted_tags, correct_pos):
            file.write(f"{word}: {predicted_pos} - {correct_pos_tag}\n")
        file.write("\n")
        for metric, value in metrics.items():
            file.write(f"{metric}: {value}\n")

def print_mfpos_output(correct_pos, words_to_predict):
    most_frequent_pos = most_freq_pos(WORDS_DICT) 
    predicted_tags = predict_mfpos(words_to_predict, most_frequent_pos)
    metrics = calculate_metrics(predicted_tags, correct_pos)

    with open(MFPOS_OUTPUT_PATH, "w") as file:
        file.write("Word         Predicted POS         Correct POS\n")
        file.write("-" * 30 + "\n")
        for (word, predicted_pos), correct_pos_tag in zip(predicted_tags, correct_pos):
            file.write(f"{word}: {predicted_pos} - {correct_pos_tag}\n")
        file.write("\n")
        for metric, value in metrics.items():
            file.write(f"{metric}: {value}\n")

         
         
         
         
         
         
         
          
def train():
    global WORDS_DICT
    WORDS_DICT = read_brown(DIRECTORY_PATH)
    print_info(WORDS_DICT)
    
def test():
    words_to_predict = []
    correct_pos = []
    test_words = read_brown(TESTING_PATH)
    print_info(test_words, IS_TESTING=True)

    for word, pos in test_words:
        words_to_predict.append(word)
        correct_pos.append(pos)
    
    print_mfpos_output(correct_pos, words_to_predict)
    print_bgp1_output(correct_pos, words_to_predict)
    print_bgp2_output(correct_pos, words_to_predict)
            
if __name__ == "__main__":
    train()
    test()
    print("Done")